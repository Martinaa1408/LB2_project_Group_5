# LAB2_project – SVM Method

This directory contains the **Support Vector Machine (SVM)** module of the project.  
It represents the **classification and optimization phase**, where the model is trained on the numerical features produced during the [Features_extraction](https://github.com/Martinaa1408/LB2_project_Group_5/edit/main/Features_extraction) stage.

The goal is to train a supervised classifier able to distinguish **signal peptide (SP)** from **non-SP** sequences based on physicochemical and compositional features extracted from the N-terminal region.

→ Notebook: [SVM_Method.ipynb](https://github.com/Martinaa1408/LB2_project_Group_5/blob/main/SVM_method/SVM_Method.ipynb)

## Objective
To build, tune, and evaluate an **SVM classifier** capable of predicting the presence of signal peptides in yeast proteins, achieving a robust trade-off between precision and recall.  
This module integrates:
- feature import from the previous notebook,  
- feature selection via Random Forest,  
- hyperparameter tuning through Grid Search,  
- full performance evaluation with confusion matrix and classification metrics.

---

## Conceptual Background
Support Vector Machines (SVMs) are **margin-based classifiers** that find an optimal hyperplane separating two classes.  
For non-linear data, the **RBF (Radial Basis Function) kernel** projects samples into a higher-dimensional space where separation becomes possible.

The optimization problem:
```math
\min_{w,b,\xi} \frac{1}{2}\|w\|^2 + C\sum_i \xi_i
\quad \text{s.t.} \quad y_i (w \cdot \phi(x_i) + b) \ge 1 - \xi_i
```
where:
- C controls the **regularization strength**,  
- ϕ(xi) is the **feature mapping function**,  
- ξi are **slack variables** allowing soft margins.

This formulation ensures a trade-off between **margin maximization** and **classification flexibility**, preventing overfitting on noisy biological data.

---

## Workflow Summary

| Step | Description | Output |
|------|--------------|---------|
| **1. Import features** | Load `ML_features.tsv` (8021 samples × 29 features) generated by the Feature Extraction module. | DataFrame with features + labels |
| **2. Preprocessing** | Apply `MinMaxScaler` to normalize variables between 0 and 1. | Scaled feature matrix |
| **3. Feature Selection (Random Forest)** | Train a Random Forest classifier (400 trees) and retain features above the median Gini importance. | 29 → **15 selected features** |
| **4. Model definition** | Initialize `sklearn.svm.SVC()` classifier. | SVC object |
| **5. Grid Search CV** | Stratified 5-fold cross-validation on C ∈ [0.1, 1, 10], kernels ∈ [linear, poly, rbf, sigmoid], γ ∈ ['scale', 'auto']. | Best SVM parameters |
| **6. Evaluation** | Compute metrics (Accuracy, Precision, Recall, F1, MCC) and visualize confusion matrix. | Performance summary |

---

## Feature Selection (Random Forest)

Feature ranking was computed via **Gini importance** on the scaled data.  
From 29 total features, the model retained **15** above the median importance threshold.

| Rank | Feature | Importance |
|------|----------|-------------|
| 1 | comp_L | 0.187 |
| 2 | α-helix mean | 0.083 |
| 3 | Charge mean | 0.062 |
| 4 | Transmembrane max | 0.055 |
| 5 | Hydrophobicity max | 0.049 |
| 6 | α-helix max | 0.048 |
| 7 | Hydrophobicity mean | 0.043 |
| 8 | Size mean | 0.041 |
| 9 | Transmembrane mean | 0.041 |
| 10 | comp_E | 0.036 |

**Top selected subset:**  
`['comp_L', 'alpha_mean', 'charge_mean', 'trans_max', 'hydro_max', 'alpha_max', 'hydro_mean', 'size_mean', 'trans_mean', 'comp_E']`

---

## Hyperparameter Optimization

### Parameter Grid
| Parameter | Values tested | Meaning |
|------------|----------------|----------|
| **C** | [0.1, 1, 10] | Regularization strength |
| **Kernel** | ['linear', 'poly', 'rbf', 'sigmoid'] | Defines mapping in feature space |
| **Gamma** | ['scale', 'auto'] | Kernel coefficient for RBF, poly and sigmoid |

**Best parameters:**  
`C = 10`, `γ = 'scale'`, `kernel = 'rbf'`

**Best CV F1:** 0.720  
**Validation accuracy (selected features):** 0.922  
**Optimal number of features:** k = 15 (val_acc = 0.922)

---

## Model Evaluation

The Support Vector Machine (RBF kernel) was evaluated at two levels:  
1. **Internal evaluation** on the full training/validation dataset (8021 proteins)  
2. **External benchmarking** on an independent test set (2006 proteins)

---

### Internal Evaluation (Training / Validation Set)

Model performance on the main dataset used for training and cross-validation.

| Metric | Value |
|:--------|-------:|
| **Accuracy** | 0.927 |
| **Precision** | 0.619 |
| **Recall (TPR)** | 0.857 |
| **F1-score** | 0.719 |
| **MCC** | 0.690 |

**Confusion Matrix**

| Actual / Predicted | Negative | Positive |
|--------------------|----------:|----------:|
| **Negative (SP–)** | 1338 | 92 |
| **Positive (SP⁺)** | 25 | 150 |

**Interpretation:**  
The model achieved a high classification accuracy (92.7%) with balanced sensitivity and precision.  
Misclassifications mainly involve borderline peptides with weak hydrophobicity or ambiguous α-helix signatures.

---

### External Evaluation (Independent Benchmark Set)

An independent dataset of 2006 yeast proteins was used to assess model generalization.

| Metric | Value |
|:--------|-------:|
| **Accuracy** | 0.921 |
| **Precision** | 0.593 |
| **Recall (TPR)** | 0.895 |
| **F1-score** | 0.714|
| **MCC** | 0.690 |

**Confusion Matrix**

| Actual / Predicted | Negative | Positive |
|--------------------|----------:|----------:|
| **Negative (SP–)** | 1653 | 134 |
| **Positive (SP⁺)** | 23 | 196 |

**Interpretation:**  
The benchmark results confirm the model’s strong generalization capability.  
Although slightly lower than training performance, the SVM preserves good recall and precision on unseen data.  
Most false positives correspond to highly hydrophobic N-terminal regions, often belonging to transmembrane proteins.

---

### Classification Reports

**Training Set**

| Class | Precision | Recall | F1-score | Support |
|:-------|:----------:|:-------:|:----------:|:---------:|
| **Negative** | 0.98 | 0.94 | 0.96 | 1430 |
| **Positive** | 0.62 | 0.86 | 0.72 | 175 |
| **Macro avg** | 0.80 | 0.90 | 0.84 | 1605 |
| **Weighted avg** | 0.94 | 0.93 | 0.93 | 1605 |

**Benchmark Set**

| Class | Precision | Recall | F1-score | Support |
|:-------|:----------:|:-------:|:----------:|:---------:|
| **Negative** | 0.99 | 0.93 | 0.95 | 1787 |
| **Positive** | 0.59 | 0.89 | 0.71 | 219 |
| **Macro avg** | 0.79 | 0.91 | 0.83 | 2006 |
| **Weighted avg** | 0.94 | 0.92 | 0.93 | 2006 |

**Summary:**  
The SVM model shows consistent high performance across both datasets, maintaining balanced precision and recall.  
MCC values above 0.75 indicate strong predictive correlation and minimal bias toward the majority class.

---

# Output Files

| File | Description |
|---|---|
|[training_svm_metrics.tsv](https://github.com/Martinaa1408/LB2_project_Group_5/blob/main/SVM_method/training_svm_metrics.tsv) | Summary of SVM model performance metrics on training data |
|[bench_svm_metrics.tsv](https://github.com/Martinaa1408/LB2_project_Group_5/blob/main/SVM_method/bench_svm_metrics.tsv) | Summary of SVM model performance metrics on benchmark data |
| [svm_final.tsv](https://github.com/Martinaa1408/LB2_project_Group_5/blob/main/SVM_method/svm_final.tsv) | Final SVM model results or processed dataset |
| [confusion_matrix_test.png](https://github.com/Martinaa1408/LB2_project_Group_5/blob/main/SVM_method/Plots/confusion_matrix_test.png) | Confusion matrix for training data |
| [confusion_matrix_bench.png](https://github.com/Martinaa1408/LB2_project_Group_5/blob/main/SVM_method/Plots/confusion_matrix_bench.png) | Confusion matrix for benchmark data |
| [RF_Gini_importance.png](https://github.com/Martinaa1408/LB2_project_Group_5/blob/main/SVM_method/Plots/RF_Gini_importance.png) | Random Forest feature importance visualization |
| [top10_RF_Gini_importance.png](https://github.com/Martinaa1408/LB2_project_Group_5/blob/main/SVM_method/Plots/top10_RF_Gini_importance.png) | Top 10 Random Forest feature importance visualization |
| [Accuracy_vs_Features.png](https://github.com/Martinaa1408/LB2_project_Group_5/blob/main/SVM_method/Plots/Accuracy_vs_Features.png) | Feature selection performance trend |
| [Precision_Recall_curve.png](https://github.com/Martinaa1408/LB2_project_Group_5/blob/main/SVM_method/Plots/Precision_Recall_curve.png) | Precision-Recall diagnostic curve |

---

## Summary and Interpretation

- The **SVM (RBF kernel)** achieved **Acc = 0.927 / MCC = 0.691** on training data and **Acc = 0.922 / MCC = 0.690** on the independent benchmark.  
- This confirms **strong generalization** and **minimal overfitting**.  
- The **Leucine composition (comp_L)**, **α-helix propensity**, and **charge mean** emerged as the strongest predictors.  
- The **Random Forest + SVM pipeline** captures non-linear feature dependencies, outperforming rule-based models.  
- Benchmark results confirm **robust transferability** to unseen sequences and consistent discrimination of true SPs.

---

**Next step →** Integrate SVM results with the rule-based *von Heijne* method and perform final comparative evaluation in the [Evaluation_and_Comparison](https://github.com/Martinaa1408/LB2_project_Group_5/edit/main/Evaluation_and_Comparison)  module.
